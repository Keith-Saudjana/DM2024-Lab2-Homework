{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Keith Saudjana\n",
    "\n",
    "Student ID: 113062421\n",
    "\n",
    "GitHub ID: Keith-Saudjana\n",
    "\n",
    "Kaggle name:\n",
    "\n",
    "Kaggle private scoreboard snapshot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim: 4.3.3\n",
      "tensorflow: 2.12.0\n",
      "keras: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import umap\n",
    "import gensim\n",
    "import tensorflow\n",
    "import keras\n",
    "import json\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"gensim: \" + gensim.__version__)\n",
    "print(\"tensorflow: \" + tensorflow.__version__)\n",
    "print(\"keras: \" + keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "# setup cuda for GPU usage\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tweets and respective ids\n",
    "tweets = pd.read_json(r'data/tweets_DM.json', lines=True)\n",
    "\n",
    "tweets = pd.json_normalize(tweets['_source'])[['tweet.tweet_id', 'tweet.text']]\n",
    "\n",
    "tweets = tweets.rename(columns={'tweet.tweet_id': 'tweet_id', 'tweet.text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text\n",
       "0        0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
       "2        0x28b412  Confident of your obedience, I write to you, k...\n",
       "3        0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>\n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...\n",
       "...           ...                                                ...\n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...\n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...\n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...\n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...\n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get emotion values\n",
    "emotion = pd.read_csv(r'data/emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x3140b1</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x368b73</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x296183</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2bd6e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2ee1dd</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x38dba0</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x300ea2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x360b99</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x22eecf</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x2fb282</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x3140b1       sadness\n",
       "1        0x368b73       disgust\n",
       "2        0x296183  anticipation\n",
       "3        0x2bd6e1           joy\n",
       "4        0x2ee1dd  anticipation\n",
       "...           ...           ...\n",
       "1455558  0x38dba0           joy\n",
       "1455559  0x300ea2           joy\n",
       "1455560  0x360b99          fear\n",
       "1455561  0x22eecf           joy\n",
       "1455562  0x2fb282  anticipation\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data identification\n",
    "data_identification = pd.read_csv(r'data/data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x227e25</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x293813</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x1e1a7e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x2156a5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x2bb9d2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id identification\n",
       "0        0x28cc61           test\n",
       "1        0x29e452          train\n",
       "2        0x2b3819          train\n",
       "3        0x2db41f           test\n",
       "4        0x2a2acc          train\n",
       "...           ...            ...\n",
       "1867530  0x227e25          train\n",
       "1867531  0x293813          train\n",
       "1867532  0x1e1a7e          train\n",
       "1867533  0x2156a5          train\n",
       "1867534  0x2bb9d2          train\n",
       "\n",
       "[1867535 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>joy</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text  \\\n",
       "0        0x376b20  People who post \"add me on #Snapchat\" must be ...   \n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2        0x28b412  Confident of your obedience, I write to you, k...   \n",
       "3        0x1cd5b0                Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>   \n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...   \n",
       "...           ...                                                ...   \n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...   \n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...   \n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...   \n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n",
       "\n",
       "              emotion identification  \n",
       "0        anticipation          train  \n",
       "1             sadness          train  \n",
       "2                 NaN           test  \n",
       "3                fear          train  \n",
       "4                 NaN           test  \n",
       "...               ...            ...  \n",
       "1867530           NaN           test  \n",
       "1867531           NaN           test  \n",
       "1867532           NaN           test  \n",
       "1867533           joy          train  \n",
       "1867534           joy          train  \n",
       "\n",
       "[1867535 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine data to singular data frame\n",
    "main_df = tweets.merge(emotion, on=\"tweet_id\", how=\"left\").merge(data_identification, on=\"tweet_id\", how=\"left\")\n",
    "\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867526</th>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867527</th>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867528</th>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text       emotion\n",
       "0        People who post \"add me on #Snapchat\" must be ...  anticipation\n",
       "1        @brianklaas As we see, Trump is dangerous to #...       sadness\n",
       "3                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          fear\n",
       "5        @RISKshow @TheKevinAllison Thx for the BEST TI...           joy\n",
       "6             Still waiting on those supplies Liscus. <LH>  anticipation\n",
       "...                                                    ...           ...\n",
       "1867526  I'm SO HAPPY!!! #NoWonder the name of this sho...           joy\n",
       "1867527  In every circumtance I'd like to be thankful t...           joy\n",
       "1867528  there's currently two girls walking around the...           joy\n",
       "1867533  Ah, corporate life, where you can date <LH> us...           joy\n",
       "1867534             Blessed to be living #Sundayvibes <LH>           joy\n",
       "\n",
       "[1455563 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract training data\n",
    "train_val_df = main_df[main_df['identification'] == 'train'].drop('identification', axis=1, inplace=False)\n",
    "train_val_df.drop('tweet_id', axis=1, inplace=True)\n",
    "\n",
    "train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867525</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867529</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                                               text emotion\n",
       "2        0x28b412  Confident of your obedience, I write to you, k...     NaN\n",
       "4        0x2de201  \"Trust is not the same as faith. A friend is s...     NaN\n",
       "9        0x218443  When do you have enough ? When are you satisfi...     NaN\n",
       "30       0x2939d5  God woke you up, now chase the day #GodsPlan #...     NaN\n",
       "33       0x26289a  In these tough times, who do YOU turn to as yo...     NaN\n",
       "...           ...                                                ...     ...\n",
       "1867525  0x2913b4  \"For this is the message that ye heard from th...     NaN\n",
       "1867529  0x2a980e  \"There is a lad here, which hath five barley l...     NaN\n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...     NaN\n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...     NaN\n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...     NaN\n",
       "\n",
       "[411972 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract testing data\n",
    "test_df = main_df[main_df['identification'] == 'test'].drop('identification', axis=1, inplace=False)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Save and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index to save to pickle\n",
    "train_val_df = train_val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "train_val_df.to_pickle(\"pkl/train_val_df.pkl\") \n",
    "test_df.to_pickle(\"pkl/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "train_val_df = pd.read_pickle(\"pkl/train_val_df.pkl\")\n",
    "test_df = pd.read_pickle(\"pkl/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger            39867\n",
       "anticipation    248935\n",
       "disgust         139101\n",
       "fear             63999\n",
       "joy             516017\n",
       "sadness         193437\n",
       "surprise         48729\n",
       "trust           205478\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of each sentiment\n",
    "train_val_df.groupby(['emotion']).count()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize sentiment amounts\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sentiment_distribution(df, figsize=(5, 3)):\n",
    "    # Get unique emotions\n",
    "    labels = df['emotion'].unique()\n",
    "    post_total = len(df)\n",
    "    \n",
    "    # calculate percentage distribution\n",
    "    df1 = df.groupby(['emotion']).count()['text']\n",
    "    df1 = df1.apply(lambda x: round(x * 100 / post_total, 3))\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.bar(df1.index, df1.values, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    plt.ylabel('% of Instances')\n",
    "    plt.xlabel('Emotion')\n",
    "    plt.title('Emotion Distribution')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_sentiment_distribution(train_val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import and download preprocessing functions and their requirements\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') \n",
    "\n",
    "# setup stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopWords.add('lh')\n",
    "\n",
    "# setup lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def show_top_100_terms(text):\n",
    "    count_vect = CountVectorizer()\n",
    "\n",
    "    # tokenize text\n",
    "    train_counts = count_vect.fit_transform(text)\n",
    "    \n",
    "    # transform count to frequency array\n",
    "    term_frequencies = np.asarray(train_counts.sum(axis=0)).flatten()\n",
    "\n",
    "    # find top 100 terms\n",
    "    top_100_indices = term_frequencies.argsort()[-100:][::-1]\n",
    "\n",
    "    top_100_terms = count_vect.get_feature_names_out()[top_100_indices]\n",
    "    top_100_terms_freq = term_frequencies[top_100_indices]\n",
    "\n",
    "    print(top_100_terms.tolist())\n",
    "    print(top_100_terms_freq.tolist())\n",
    "\n",
    "    top_100_freq_data = pd.DataFrame({\n",
    "        'term': top_100_terms,\n",
    "        'freq': top_100_terms_freq\n",
    "    })\n",
    "\n",
    "    # bar plot visualization\n",
    "    fig = px.bar(top_100_freq_data, x='term', y='freq', title='Top 100 Term Frequencies',\n",
    "                 text='freq', color_discrete_sequence=['red'])\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Terms',\n",
    "        yaxis_title='Frequencies',\n",
    "        width=1000,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing of a single text\n",
    "def process_single_text(text):\n",
    "    # convert all words to lower case\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # remove all stop words and not alphabetical values\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in stopWords]\n",
    "\n",
    "    # lemmatize other words\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old preprocess code\n",
    "def preprocess_text(texts):\n",
    "    if isinstance(texts, pd.Series):\n",
    "        return texts.apply(process_single_text).tolist()\n",
    "    elif isinstance(texts, list):\n",
    "        return list(map(process_single_text, texts))\n",
    "    elif isinstance(texts, str):\n",
    "        return [process_single_text(texts)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize multithreading to optimize preprocessing of list of texts\n",
    "def preprocess_text_optimized(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = pd.Series([texts])\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        processed_texts = list(executor.map(process_single_text, texts))\n",
    "    \n",
    "    return processed_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_train_val_df = train_val_df.copy()\n",
    "preprocess_test_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature for preprocessed texts\n",
    "preprocess_train_val_df['preprocessed'] = preprocess_text_optimized(preprocess_train_val_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people post add snapchat must dehydrated cuz man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brianklaas see trump dangerous freepress aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "      <td>issa stalking tasha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "      <td>riskshow thekevinallison thx best time tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still waiting supply liscus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>joy</td>\n",
       "      <td>happy nowonder name show happy happysyfy syfy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>joy</td>\n",
       "      <td>every circumtance like thankful almighty jesus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>joy</td>\n",
       "      <td>currently two girl walking around library hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>joy</td>\n",
       "      <td>ah corporate life date using relative anachron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>joy</td>\n",
       "      <td>blessed living sundayvibes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text       emotion  \\\n",
       "0        People who post \"add me on #Snapchat\" must be ...  anticipation   \n",
       "1        @brianklaas As we see, Trump is dangerous to #...       sadness   \n",
       "2                      Now ISSA is stalking Tasha ðŸ˜‚ðŸ˜‚ðŸ˜‚ <LH>          fear   \n",
       "3        @RISKshow @TheKevinAllison Thx for the BEST TI...           joy   \n",
       "4             Still waiting on those supplies Liscus. <LH>  anticipation   \n",
       "...                                                    ...           ...   \n",
       "1455558  I'm SO HAPPY!!! #NoWonder the name of this sho...           joy   \n",
       "1455559  In every circumtance I'd like to be thankful t...           joy   \n",
       "1455560  there's currently two girls walking around the...           joy   \n",
       "1455561  Ah, corporate life, where you can date <LH> us...           joy   \n",
       "1455562             Blessed to be living #Sundayvibes <LH>           joy   \n",
       "\n",
       "                                              preprocessed  \n",
       "0         people post add snapchat must dehydrated cuz man  \n",
       "1        brianklaas see trump dangerous freepress aroun...  \n",
       "2                                      issa stalking tasha  \n",
       "3        riskshow thekevinallison thx best time tonight...  \n",
       "4                              still waiting supply liscus  \n",
       "...                                                    ...  \n",
       "1455558      happy nowonder name show happy happysyfy syfy  \n",
       "1455559  every circumtance like thankful almighty jesus...  \n",
       "1455560  currently two girl walking around library hand...  \n",
       "1455561  ah corporate life date using relative anachron...  \n",
       "1455562                         blessed living sundayvibes  \n",
       "\n",
       "[1455563 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature for preprocessed texts\n",
    "preprocess_test_df['preprocessed'] = preprocess_text_optimized(preprocess_test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>confident obedience write knowing even ask phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trust faith friend someone trust putting faith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enough satisfied goal really money materialism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>god woke chase day godsplan godswork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tough time turn symbol hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>\"For this is the message that ye heard from th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>message ye heard beginning love one another jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>\"There is a lad here, which hath five barley l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lad hath five barley loaf two small fish among...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>buy last ticket remaining show sell mixedfeeli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>swear hard work gone pay one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>card left idea get parcel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_id                                               text emotion  \\\n",
       "0       0x28b412  Confident of your obedience, I write to you, k...     NaN   \n",
       "1       0x2de201  \"Trust is not the same as faith. A friend is s...     NaN   \n",
       "2       0x218443  When do you have enough ? When are you satisfi...     NaN   \n",
       "3       0x2939d5  God woke you up, now chase the day #GodsPlan #...     NaN   \n",
       "4       0x26289a  In these tough times, who do YOU turn to as yo...     NaN   \n",
       "...          ...                                                ...     ...   \n",
       "411967  0x2913b4  \"For this is the message that ye heard from th...     NaN   \n",
       "411968  0x2a980e  \"There is a lad here, which hath five barley l...     NaN   \n",
       "411969  0x316b80  When you buy the last 2 tickets remaining for ...     NaN   \n",
       "411970  0x29d0cb  I swear all this hard work gone pay off one da...     NaN   \n",
       "411971  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...     NaN   \n",
       "\n",
       "                                             preprocessed  \n",
       "0       confident obedience write knowing even ask phi...  \n",
       "1       trust faith friend someone trust putting faith...  \n",
       "2       enough satisfied goal really money materialism...  \n",
       "3                    god woke chase day godsplan godswork  \n",
       "4                             tough time turn symbol hope  \n",
       "...                                                   ...  \n",
       "411967  message ye heard beginning love one another jo...  \n",
       "411968  lad hath five barley loaf two small fish among...  \n",
       "411969  buy last ticket remaining show sell mixedfeeli...  \n",
       "411970                       swear hard work gone pay one  \n",
       "411971                          card left idea get parcel  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save new data frames\n",
    "preprocess_train_val_df.to_pickle(\"pkl/preprocess_train_val_df.pkl\") \n",
    "preprocess_test_df.to_pickle(\"pkl/preprocess_test_df.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load new data frames\n",
    "preprocess_train_val_df = pd.read_pickle(\"pkl/preprocess_train_val_df.pkl\")\n",
    "preprocess_test_df = pd.read_pickle(\"pkl/preprocess_test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'life', 'day', 'today', 'like', 'god', 'get', 'one', 'time', 'good', 'people', 'make', 'know', 'got', 'go', 'see', 'never', 'thank', 'pip', 'thing', 'new', 'need', 'come', 'work', 'want', 'great', 'happy', 'realdonaldtrump', 'much', 'back', 'ca', 'still', 'say', 'year', 'thanks', 'lot', 'going', 'always', 'give', 'let', 'would', 'way', 'really', 'best', 'feel', 'week', 'dream', 'right', 'world', 'think', 'even', 'please', 'last', 'first', 'friend', 'look', 'hope', 'moment', 'another', 'man', 'night', 'take', 'total', 'morning', 'ever', 'keep', 'every', 'closed', 'follow', 'someone', 'better', 'feeling', 'show', 'blessed', 'eurusd', 'amazing', 'could', 'well', 'help', 'tonight', 'play', 'guy', 'everyone', 'sad', 'family', 'made', 'believe', 'everything', 'many', 'na', 'home', 'jesus', 'game', 'wait', 'girl', 'nothing', 'watching', 'next', 'trump', 'done']\n",
      "[88998, 83371, 74671, 68650, 59795, 59485, 54922, 53163, 49846, 47004, 44745, 42816, 38642, 36943, 33679, 33389, 33191, 33113, 32407, 31810, 31557, 30646, 29166, 28713, 28196, 28104, 28103, 27631, 26684, 26392, 25547, 25448, 24912, 24748, 24534, 24514, 24458, 24260, 23839, 23820, 23807, 23709, 23623, 22855, 22552, 22124, 21930, 21913, 21650, 21648, 21454, 20636, 20541, 20262, 19927, 19849, 19768, 19542, 19154, 18933, 18587, 18521, 18300, 17639, 17334, 17250, 17223, 17209, 17110, 17019, 16750, 16743, 16724, 16367, 16186, 15857, 15476, 15472, 15283, 15170, 14935, 14885, 14841, 14696, 14628, 14444, 14173, 14112, 13999, 13999, 13708, 13501, 13438, 13366, 13345, 13292, 13008, 12941, 12919, 12829]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "term=%{x}<br>freq=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "red",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          88998,
          83371,
          74671,
          68650,
          59795,
          59485,
          54922,
          53163,
          49846,
          47004,
          44745,
          42816,
          38642,
          36943,
          33679,
          33389,
          33191,
          33113,
          32407,
          31810,
          31557,
          30646,
          29166,
          28713,
          28196,
          28104,
          28103,
          27631,
          26684,
          26392,
          25547,
          25448,
          24912,
          24748,
          24534,
          24514,
          24458,
          24260,
          23839,
          23820,
          23807,
          23709,
          23623,
          22855,
          22552,
          22124,
          21930,
          21913,
          21650,
          21648,
          21454,
          20636,
          20541,
          20262,
          19927,
          19849,
          19768,
          19542,
          19154,
          18933,
          18587,
          18521,
          18300,
          17639,
          17334,
          17250,
          17223,
          17209,
          17110,
          17019,
          16750,
          16743,
          16724,
          16367,
          16186,
          15857,
          15476,
          15472,
          15283,
          15170,
          14935,
          14885,
          14841,
          14696,
          14628,
          14444,
          14173,
          14112,
          13999,
          13999,
          13708,
          13501,
          13438,
          13366,
          13345,
          13292,
          13008,
          12941,
          12919,
          12829
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "love",
          "life",
          "day",
          "today",
          "like",
          "god",
          "get",
          "one",
          "time",
          "good",
          "people",
          "make",
          "know",
          "got",
          "go",
          "see",
          "never",
          "thank",
          "pip",
          "thing",
          "new",
          "need",
          "come",
          "work",
          "want",
          "great",
          "happy",
          "realdonaldtrump",
          "much",
          "back",
          "ca",
          "still",
          "say",
          "year",
          "thanks",
          "lot",
          "going",
          "always",
          "give",
          "let",
          "would",
          "way",
          "really",
          "best",
          "feel",
          "week",
          "dream",
          "right",
          "world",
          "think",
          "even",
          "please",
          "last",
          "first",
          "friend",
          "look",
          "hope",
          "moment",
          "another",
          "man",
          "night",
          "take",
          "total",
          "morning",
          "ever",
          "keep",
          "every",
          "closed",
          "follow",
          "someone",
          "better",
          "feeling",
          "show",
          "blessed",
          "eurusd",
          "amazing",
          "could",
          "well",
          "help",
          "tonight",
          "play",
          "guy",
          "everyone",
          "sad",
          "family",
          "made",
          "believe",
          "everything",
          "many",
          "na",
          "home",
          "jesus",
          "game",
          "wait",
          "girl",
          "nothing",
          "watching",
          "next",
          "trump",
          "done"
         ],
         "xaxis": "x",
         "y": [
          88998,
          83371,
          74671,
          68650,
          59795,
          59485,
          54922,
          53163,
          49846,
          47004,
          44745,
          42816,
          38642,
          36943,
          33679,
          33389,
          33191,
          33113,
          32407,
          31810,
          31557,
          30646,
          29166,
          28713,
          28196,
          28104,
          28103,
          27631,
          26684,
          26392,
          25547,
          25448,
          24912,
          24748,
          24534,
          24514,
          24458,
          24260,
          23839,
          23820,
          23807,
          23709,
          23623,
          22855,
          22552,
          22124,
          21930,
          21913,
          21650,
          21648,
          21454,
          20636,
          20541,
          20262,
          19927,
          19849,
          19768,
          19542,
          19154,
          18933,
          18587,
          18521,
          18300,
          17639,
          17334,
          17250,
          17223,
          17209,
          17110,
          17019,
          16750,
          16743,
          16724,
          16367,
          16186,
          15857,
          15476,
          15472,
          15283,
          15170,
          14935,
          14885,
          14841,
          14696,
          14628,
          14444,
          14173,
          14112,
          13999,
          13999,
          13708,
          13501,
          13438,
          13366,
          13345,
          13292,
          13008,
          12941,
          12919,
          12829
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 500,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 100 Term Frequencies"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Terms"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Frequencies"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_top_100_terms(preprocess_train_val_df['preprocessed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "**Things to try:**\n",
    "- Feature engineering (Word2Vec, PCA, LDA, FastText, Clustering)\n",
    "- Fix dataset skew\n",
    "\n",
    "**Models:**\n",
    "- BERT (Transformer): 110 million parameters\n",
    "- DistilBERT (Transformer): 66 million parameters\n",
    "- MiniLM (Trannsformer): 15 million or 33 million parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for train and validation split\n",
    "# texts = preprocess_train_val_df['text'].values\n",
    "texts = preprocess_train_val_df['preprocessed'].values\n",
    "labels = preprocess_train_val_df['emotion'].values\n",
    "\n",
    "# convert emotion values to categorical integers\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'anticipation': 1,\n",
       " 'disgust': 2,\n",
       " 'fear': 3,\n",
       " 'joy': 4,\n",
       " 'sadness': 5,\n",
       " 'surprise': 6,\n",
       " 'trust': 7}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create emotion dictionary for easy conversion\n",
    "label_mapping = {original: encoded for original, encoded in zip(encoder.classes_, range(len(encoder.classes_)))}\n",
    "\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'anger',\n",
       " 1: 'anticipation',\n",
       " 2: 'disgust',\n",
       " 3: 'fear',\n",
       " 4: 'joy',\n",
       " 5: 'sadness',\n",
       " 6: 'surprise',\n",
       " 7: 'trust'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create reverse emotion dictionary for easy conversion\n",
    "reverse_mapping = {encoded: original for original, encoded in label_mapping.items()}\n",
    "\n",
    "reverse_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data to training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, encoded_labels, stratify = encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test data\n",
    "X_test = preprocess_test_df['preprocessed'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable for data preparation\n",
    "vocab_size = 3000\n",
    "oov_tok = ''\n",
    "embedding_dim = 100\n",
    "max_length = 200\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize tokenizaer\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "# fit tokenizer on training data to build word index\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# retreive word index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Convert data into sequences of integers \n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the data sequences to ensure uniform length\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=max_length)\n",
    "val_padded = pad_sequences(val_sequences, padding='post', maxlen=max_length)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 200, 100)          300000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              84480     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8)                 200       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 387,776\n",
      "Trainable params: 387,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(vocab_size, embedding_dim, input_shape=(max_length,)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "    keras.layers.Dense(24, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Define learning rate and decay\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Create Adam optimizer with learning rate schedule\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# compile model with loss function, optimizer, and metrics\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "34115/34115 [==============================] - 3656s 107ms/step - loss: 1.3593 - accuracy: 0.5102 - val_loss: 1.3202 - val_accuracy: 0.5234\n",
      "Epoch 2/5\n",
      "34115/34115 [==============================] - 3512s 103ms/step - loss: 1.3013 - accuracy: 0.5301 - val_loss: 1.3058 - val_accuracy: 0.5283\n",
      "Epoch 3/5\n",
      "34115/34115 [==============================] - 3465s 102ms/step - loss: 1.2774 - accuracy: 0.5388 - val_loss: 1.3001 - val_accuracy: 0.5311\n",
      "Epoch 4/5\n",
      "34115/34115 [==============================] - 3468s 102ms/step - loss: 1.2585 - accuracy: 0.5458 - val_loss: 1.3003 - val_accuracy: 0.5308\n",
      "Epoch 5/5\n",
      "34115/34115 [==============================] - 3471s 102ms/step - loss: 1.2419 - accuracy: 0.5518 - val_loss: 1.3022 - val_accuracy: 0.5304\n"
     ]
    }
   ],
   "source": [
    "# train and validate model\n",
    "num_epochs = 5\n",
    "history = model.fit(train_padded, y_train, \n",
    "                    epochs=num_epochs, verbose=1, \n",
    "                    validation_data=(val_padded, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(r'lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 200], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_3'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py:868\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_layer.py:153\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;129;01mand\u001b[39;00m ragged:\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized keyword arguments: ['batch_shape']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheckpoints\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlstm_model_preprocessed.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# predict test data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m prediction \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(test_padded)\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saving_api.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         )\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    213\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    214\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saving_lib.py:277\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    274\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\saving_lib.py:242\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 242\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\serialization_lib.py:502\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m--> 502\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\sequential.py:476\u001b[0m, in \u001b[0;36mSequential.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    474\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_config \u001b[38;5;129;01min\u001b[39;00m layer_configs:\n\u001b[1;32m--> 476\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(layer)\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m model\u001b[38;5;241m.\u001b[39minputs\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m build_input_shape\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(build_input_shape, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m))\n\u001b[0;32m    485\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\serialization.py:265\u001b[0m, in \u001b[0;36mdeserialize\u001b[1;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[0;32m    258\u001b[0m         config,\n\u001b[0;32m    259\u001b[0m         module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[0;32m    260\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    261\u001b[0m         printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# To be replaced by new serialization_lib\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\saving\\legacy\\serialization.py:513\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[1;32m--> 513\u001b[0m             deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[1;32mc:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\base_layer.py:870\u001b[0m, in \u001b[0;36mLayer.from_config\u001b[1;34m(cls, config)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Error when deserializing class 'InputLayer' using config={'batch_shape': [None, 200], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_3'}.\n\nException encountered: Unrecognized keyword arguments: ['batch_shape']"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# load model\n",
    "loaded_model = load_model(r'checkpoints\\LSTM\\lstm_model_preprocessed.keras')\n",
    "\n",
    "# predict test data\n",
    "prediction = loaded_model.predict(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert logits to emotion values\n",
    "def convert_logits(logits_list):\n",
    "    predictions = []\n",
    "    \n",
    "    for logits in logits_list:\n",
    "        # find highest value logit\n",
    "        logits = np.array(logits)\n",
    "        max_index = np.argmax(logits)\n",
    "        \n",
    "        # convert highest value logit to emotion value\n",
    "        predictions.append(reverse_mapping[max_index])\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for submission\n",
    "answer_df = pd.DataFrame()\n",
    "\n",
    "answer_df['id'] = test_df['tweet_id']\n",
    "answer_df['emotion'] = convert_logits(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2913b4</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x2a980e</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28b412         trust\n",
       "1       0x2de201  anticipation\n",
       "2       0x218443       disgust\n",
       "3       0x2939d5         trust\n",
       "4       0x26289a         trust\n",
       "...          ...           ...\n",
       "411967  0x2913b4  anticipation\n",
       "411968  0x2a980e      surprise\n",
       "411969  0x316b80         anger\n",
       "411970  0x29d0cb         anger\n",
       "411971  0x2a6a4f      surprise\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv file\n",
    "answer_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer (Unused - Takes too long to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "torch: 2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, BertForSequenceClassification, BertTokenizer, get_scheduler\n",
    "from sentence_transformers import SentenceTransformer, InputExample, LoggingHandler\n",
    "from torch.utils.data import DataLoader, TensorDataset, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "print(\"torch: \" + torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 8\n",
    "max_length = 64\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b04cafaadf849bc90f37a12efb8f78c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--microsoft--MiniLM-L12-H384-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1813bd6247343cf837b2910de808070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bbb57c48744ed7be2ece1a6db8fc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf86254d66445f9810cc970ca758aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed1ab3e64824c6982609732fcd9f277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=384, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'microsoft/MiniLM-L12-H384-uncased'\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(texts, labels=None, max_seq_len=max_length, batch_size=batch_size, shuffle=True):\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    if isinstance(texts, np.ndarray):\n",
    "        texts = texts.tolist()\n",
    "\n",
    "    encoded_inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "    input_ids = encoded_inputs['input_ids']\n",
    "    attention_mask = encoded_inputs['attention_mask']\n",
    "    token_type_ids = encoded_inputs.get('token_type_ids', torch.zeros_like(input_ids))\n",
    "    \n",
    "    if labels is not None:\n",
    "        if isinstance(labels, pd.Series):\n",
    "            labels = labels.tolist()\n",
    "        label_ids = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(input_ids, attention_mask, token_type_ids, label_ids)\n",
    "    else:\n",
    "        dataset = TensorDataset(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "    return DataLoader(dataset, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(X_train, y_train)\n",
    "val_dataloader = get_dataloader(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = get_dataloader(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels = []\n",
    "    correct_labels = []\n",
    "\n",
    "    for step in enumerate(tqdm(dataloader, desc = 'Evaluation iteration')):\n",
    "        batch = tuple (t.to(device) for t in batch)\n",
    "        input_ids, input_mask, token_type_id, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask, token_type_id=token_type_id, labels=label_ids)\n",
    "\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "\n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().time()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "\n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "NUM_TRAIN_EPOCHS = 5\n",
    "LEARNING_RATE = 5e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_GRAD_NORM = 5\n",
    "\n",
    "num_train_steps = int(len(train_dataloader.dataset) / batch_size / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(WARMUP_PROPORTION * num_train_steps)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = get_scheduler('linear', optimizer=optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import trange, tqdm\n",
    "# from tqdm.notebook import tqdm as tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"checkpoints\\BERT\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "PATIENCE = 2\n",
    "\n",
    "loss_history = []\n",
    "no_improvement = 0\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)  \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "    test_loss, _, _ = evaluate(model, test_dataloader)\n",
    "    \n",
    "    print(\"Loss history:\", loss_history)\n",
    "    print(\"test loss:\", test_loss)\n",
    "    \n",
    "    if len(loss_history) == 0 or test_loss < min(loss_history):\n",
    "        no_improvement = 0\n",
    "        model_to_save = model.module if hasattr(model, 'module') else model\n",
    "        output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "        torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    if no_improvement >= PATIENCE: \n",
    "        print(\"No improvement on development set. Finish training.\")\n",
    "        break\n",
    "        \n",
    "    \n",
    "    loss_history.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, state_dict=model_state_dict, num_labels = len(label_mapping))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "_, train_correct, train_predicted = evaluate(model, train_dataloader)\n",
    "_, val_correct, val_predicted = evaluate(model, val_dataloader)\n",
    "_, test_correct, test_predicted = evaluate(model, test_dataloader)\n",
    "\n",
    "print(\"Training performance:\", precision_recall_fscore_support(train_correct, train_predicted, average=\"micro\"))\n",
    "print(\"Development performance:\", precision_recall_fscore_support(val_correct, val_predicted, average=\"micro\"))\n",
    "print(\"Test performance:\", precision_recall_fscore_support(test_correct, test_predicted, average=\"micro\"))\n",
    "\n",
    "bert_accuracy = np.mean(test_predicted == test_correct)\n",
    "\n",
    "print(classification_report(test_correct, test_predicted, target_names=label_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Report\n",
    "\n",
    "**Preprocessing**  \n",
    "The text preprocessing process of the model utilizes transformation, removal of stop words (and non alphabetical values), and lemmatization:\n",
    "- transformation is done by converting all words to their lower case form.\n",
    "- stop words are taken from nltk's list of stop words. Other words are added that just seem odd to be included such as lh, which appears in the top 100 terms for some reason.\n",
    "- non alphabetical values are also removed as they do not add much value to sentiment (except perhaps punctuation).\n",
    "- lemmatization is performed in order to minimize word variety.\n",
    "\n",
    "**Feature Creation**  \n",
    "Throughout the entire model, only one feature was created which is the preprocessed texts feature which is used as the input for the training, validation, and testing instead of the usual text.\n",
    "\n",
    "**Model**  \n",
    "The model used is the LSTM model due to its simplicity and because they are designed to capture sequential dependencies in data such as text. Sentiment usually depends on the context provided by the sequence of words and LSTM is designed to 'remember' earlier words in the sequence which helps to determine the sentiment.\n",
    "\n",
    "The model is fed the preprocessed texts from the feature creation step. It will also be tested by preprocessed test data. Due to the sheer size of the dataset, training is only conducted for 5 epochs which already shows promising results (~42%).\n",
    "\n",
    "Initially a BERT model was meant to be used but due to computational limitations, it is scrapped. The code for the BERT model is provided but no comments are given.\n",
    "\n",
    "**Result Analysis**  \n",
    "- Baseline Model (only LSTM): ~43%  \n",
    "- LSTM + Preprocessing:   \n",
    "- LSTM + Data Balancing + Preprocessing: ~32%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
